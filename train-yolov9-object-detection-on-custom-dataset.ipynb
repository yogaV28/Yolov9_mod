<<<<<<< HEAD
version https://git-lfs.github.com/spec/v1
oid sha256:f960bb7cba84ad3ed81f49c6e2efee1d8a566b5b59c08fb1509d68db0946238a
size 197748
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m09A8n4djDwY"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5hX88yficL7",
    "outputId": "43bfb50e-0aa8-4ce4-cf74-389545fe8357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialize NVML: Unknown Error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTprsNjHja4l"
   },
   "source": [
    "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rowKDIT-jJ9k",
    "outputId": "e15d746f-d9dc-4cad-d3cd-946d49783189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/yolov9_nit/yolov9_clone\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWRGGT7Zjjbq"
   },
   "source": [
    "## Clone and Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WyY-fboBLZB"
   },
   "source": [
    "**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pixgo4qnjdoU"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/SkalskiP/yolov9.git\n",
    "%cd yolov9\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcx7KoNzqpgz"
   },
   "source": [
    "**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPGqlohQqgAO"
   },
   "outputs": [],
   "source": [
    "!pip install -q roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8oLIkX2l2P0"
   },
   "source": [
    "## Download model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FieRuZnB4wH"
   },
   "source": [
    "**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7j3aUE7l1Je"
   },
   "outputs": [],
   "source": [
    "# Create the weights directory if it doesn't exist\n",
    "!mkdir -p /app/yolov9_nit/yolov9_clone/weights\n",
    "\n",
    "# Download the weights using curl\n",
    "!curl -L -o /app/yolov9_nit/yolov9_clone/weights/yolov9-c.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
    "!curl -L -o /app/yolov9_nit/yolov9_clone/weights/yolov9-e.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
    "!curl -L -o /app/yolov9_nit/yolov9_clone/weights/gelan-c.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
    "!curl -L -o /app/yolov9_nit/yolov9_clone/weights/gelan-e.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y curl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Au6np1JS8eRB",
    "outputId": "ddf7bd59-9fd0-43a2-e743-9a52852930ce"
   },
   "outputs": [],
   "source": [
    "!ls -la /app/yolov9_nit/yolov9_clone/weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check the number of GPUs available\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Check the name of the GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Allocated GPU memory: {torch.cuda.memory_allocated(0) / 1024 ** 2} MB\")\n",
    "    print(f\"Free GPU memory: {torch.cuda.memory_reserved(0) / 1024 ** 2} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y nvidia-cuda-toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialize NVML: Unknown Error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dg29vEyLkTDA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIKNGnN2kcTp"
   },
   "source": [
    "**NOTE:** If you want to run inference using your own file as input, simply upload image to Google Colab and update `SOURCE_IMAGE_PATH` with the path leading to your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUiPMLxmj4Ze"
   },
   "outputs": [],
   "source": [
    "!wget -P {HOME}/data -q https://media.roboflow.com/notebooks/examples/dog.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiqFDio2kX8i"
   },
   "outputs": [],
   "source": [
    "SOURCE_IMAGE_PATH = f\"{HOME}/dog.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dlfABN6m-LL"
   },
   "source": [
    "## Detection with pre-trained COCO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EPCiYcFComZ"
   },
   "source": [
    "### gelan-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzGyLetWoTWp",
    "outputId": "c51e7975-c75f-474a-e217-6e070f4176f8"
   },
   "outputs": [],
   "source": [
    "!python3 detect.py --weights weights/gelan-c.pt --conf 0.1 --source car-detection-2-1/test/images --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hflXfkBt3N0k"
   },
   "source": [
    "**NOTE:** By default, the results of each subsequent inference sessions are saved in `{HOME}/yolov9/runs/detect/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sAE1P1BxpHYL",
    "outputId": "14444f6d-0f1d-48f0-c31f-d70cea929072"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"yolov9/runs/detect/exp\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCEIP-jFCsRN"
   },
   "source": [
    "## yolov9-e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEQALIFaCuoX",
    "outputId": "65539362-623f-4217-d714-fdfe6bd28827"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights {HOME}/weights/yolov9-c.pt --conf 0.1 --source {HOME}/data/dog.jpeg --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "llm4xIE_CyXJ",
    "outputId": "3b222b26-5668-401b-c1de-4f524bd841a9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{HOME}/yolov9/runs/detect/exp2/dog.jpeg\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7fZKrxsq_td",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Authenticate and Download the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5yx2GkI2P7Q"
   },
   "source": [
    "**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyLpftfU2Q1U"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/yolov9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eosmGt89vMO1"
   },
   "source": [
    "**NOTE:** In this tutorial, I will use the [football-players-detection](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc) dataset. Feel free to replace it with your dataset in YOLO format or use another dataset available on [Roboflow Universe](https://universe.roboflow.com). Additionally, if you plan to deploy your model to Roboflow after training, make sure you are the owner of the dataset and that no model is associated with the version of the dataset you are going to training on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTbGpF2IsZ24"
   },
   "source": [
    "## Train Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N68Bdf4FsMYW"
   },
   "outputs": [],
   "source": [
    "# Change to the appropriate directory\n",
    "%cd /app/yolov9_nit/yolov9_clone\n",
    "\n",
    "# Install the required packages from requirements.txt\n",
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N68Bdf4FsMYW",
    "scrolled": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the appropriate directory\n",
    "%cd /app/yolov9_nit/yolov9_clone\n",
    "\n",
    "# Install the required package\n",
    "%pip install wandb\n",
    "\n",
    "# Run the training script\n",
    "!python3 train.py \\\n",
    "--batch 4 --epochs 100 --img 48 --device 0 --min-items 0 --multi-scale \\\n",
    "--data data.yaml --optimizer AdamW --noautoanchor \\\n",
    "--weights weights/gelan-c.pt \\\n",
    "--cfg models/detect/gelan-c.yaml \\\n",
    "--hyp hyp.scratch-high.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libglib2.0-0\n",
    "!apt-get install -y libgl1-mesa-glx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confTreshold: 0.45              # Detection confidence threshold updated to where F1 score peaks\n",
    "nmsTreshold : 0.45              # nms threshold remains the same\n",
    "maxSupportBatchSize: 1          # Support max input batch size remains the same\n",
    "quantizationInfer: \"INT8\"       # Support FP32 or FP16 quantization remains the same\n",
    "onnxFile: \"yolov9-c.onnx\"       # The currently used onnx model file remains the same\n",
    "engineFile: \"yolov9-c.engine\"   # Automatically generate file names for the Tensorrt inference engine remains the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import pycuda\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "# Load ONNX model\n",
    "onnx_model = onnx.load(\"/home/srmist/Desktop/yolov9/best.onnx\")\n",
    "\n",
    "# Create TensorRT engine from ONNX model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    builder.max_workspace_size = 1 << 28  # 256MiB\n",
    "    builder.max_batch_size = 1\n",
    "    builder.fp16_mode = False  # Set to False for INT8 quantization\n",
    "    builder.int8_mode = True\n",
    "    builder.int8_calibrator = ...  # Set INT8 calibrator if necessary\n",
    "    parser.parse(onnx_model.SerializeToString())\n",
    "\n",
    "    # Set detection and NMS thresholds\n",
    "    network.get_output(0).set_dynamic_range(-1.0, 1.0)\n",
    "    network.get_output(1).set_dynamic_range(-1.0, 1.0)\n",
    "    network.get_output(2).set_dynamic_range(-1.0, 1.0)\n",
    "    network.get_output(3).set_dynamic_range(0.0, 255.0)\n",
    "    network.get_output(4).set_dynamic_range(0.0, 255.0)\n",
    "    network.get_output(5).set_dynamic_range(0.0, 255.0)\n",
    "\n",
    "    # Build TensorRT engine\n",
    "    engine = builder.build_cuda_engine(network)\n",
    "\n",
    "    # Save TensorRT engine to file\n",
    "    with open(\"/home/srmist/Desktop/yolov9/best.engine\", \"wb\") as f:\n",
    "        f.write(engine.serialize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir configs\n",
    "mv ~/home/srmist/Desktop/yolov9/best.onxx configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clearml\n",
    "clearml.browser_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N68Bdf4FsMYW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade clearml tensorboard ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpCwjSUg2Mrw",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Examine Training Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHsMq7wc3bve"
   },
   "source": [
    "**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WslwgMAW2Euc",
    "outputId": "144b5202-56a6-4782-f797-763010939665"
   },
   "outputs": [],
   "source": [
    "!ls {HOME}/yolov9/runs/train/exp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "grirpuCstpZE",
    "outputId": "cd9b75ea-4451-4493-8a48-6ca4e848f075"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%cd /home/srmist/Desktop/yolov9/\n",
    "\n",
    "Image(filename=f\"runs/train/exp9/results.png\", width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "qggEg7Hv1zJ6",
    "outputId": "9fcd5ba4-da6c-45d7-a051-b0b88d7da06d"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"runs/train/exp9/confusion_matrix.png\", width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "Xja2fjTl32Ml",
    "outputId": "dc6b1c52-b42b-4e7b-c64d-11647e6aead9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"runs/exp9/val_batch0_pred.jpg\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih1rk9O_4CYG"
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoZv8kNE4NxS",
    "outputId": "a13455e7-0524-46e5-c99e-4d930065b140"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/yolov9\n",
    "\n",
    "!python val.py \\\n",
    "--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJJ5fiqT6mEq"
   },
   "source": [
    "## Inference with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vnrn9cwIsUs"
   },
   "outputs": [],
   "source": [
    "!python detect.py \\\n",
    "--img 1280 --conf 0.1 --device 0 \\\n",
    "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n",
    "--source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPbhTtVXtM4Q"
   },
   "source": [
    "**NOTE:** Just like behore, the inference results have been saved in the appropriate directory inside `{HOME}/yolov9/runs/detect/`. Let's examine few of those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "XoV4sGOKJPZj",
    "outputId": "35982356-6054-4497-ca3e-b35fe7377c01"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp3/*.jpg')[:2]:\n",
    "      display(Image(filename=image_path, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMTTVZU48DdJ"
   },
   "source": [
    "## BONUS: Deploy YOLOv9 Model with Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoDQAk5arRfm"
   },
   "source": [
    "**NOTE:** To deploy the model and display inference results, we will need two additional packages - [`inference`](https://pypi.org/project/inference) and [`supervision`](https://pypi.org/project/supervision). Let's install and import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn6YWeaa8bdZ"
   },
   "outputs": [],
   "source": [
    "!pip install -q inference supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BauaNyA8wrj"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import getpass\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "from inference import get_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV-BnNU-7_4h",
    "outputId": "221953fd-3c6d-4cbc-fb5a-b4847fe4dd80"
   },
   "outputs": [],
   "source": [
    "version.deploy(model_type=\"yolov9\", model_path=f\"{HOME}/yolov9/runs/train/exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH30xwvAx1nb"
   },
   "source": [
    "**NOTE:** Now we can download our model anywhere using the assigned `model_id` denoted by `[2]`. In my case `football-players-detection-3zvbc/6`. To download the model you will need your [`ROBOFLOW_API_KEY`](https://docs.roboflow.com/api-reference/authentication).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAB-5ZMM87w3",
    "outputId": "3eb4a88c-0fb5-4dcb-a352-ead516e255a0"
   },
   "outputs": [],
   "source": [
    "ROBOFLOW_API_KEY = getpass.getpass()\n",
    "\n",
    "model = get_model(model_id=\"football-players-detection-3zvbc/8\", api_key=ROBOFLOW_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pGSLZ8Fz5qO"
   },
   "source": [
    "**NOTE:** Let's pick random image from our test subset and detect objects using newly fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aes2oRxi9Kpv"
   },
   "outputs": [],
   "source": [
    "image_paths = sv.list_files_with_extensions(\n",
    "    directory=f\"{dataset.location}/test/images\",\n",
    "    extensions=['png', 'jpg', 'jpeg']\n",
    ")\n",
    "image_path = random.choice(image_paths)\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "result = model.infer(image, confidence=0.1)[0]\n",
    "detections = sv.Detections.from_inference(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Xdr3Vp1uir"
   },
   "source": [
    "**NOTE:** Finally, let's use supervision and [annotate](https://supervision.roboflow.com/develop/annotators/) our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "Kq0BKx1_-kAy",
    "outputId": "cf68a6d0-4d0c-45ae-be58-633d2af6703a"
   },
   "outputs": [],
   "source": [
    "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "\n",
    "annotated_image = image.copy()\n",
    "annotated_image = bounding_box_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> 36bd69c (Initial commit)
